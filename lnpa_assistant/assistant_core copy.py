import os
import re
import time
import json
import logging
import requests
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from gpt4all import GPT4All
import PyPDF2
from docx import Document
import hashlib

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class DocumentChunk:
    text: str
    metadata: Dict
    embedding: Optional[List[float]] = None

class EnhancedLNPAssistant:
    def __init__(self, data_dir="documents", persist_dir="./chroma_db", config_path="config.json"):
        self.data_dir = data_dir
        self.persist_dir = persist_dir
        self.config_path = config_path
        self.config = self.load_config()
        
        self.documents = []
        self.embedding_model = None
        self.llm_client = None
        self.vector_db = None
        self.collection = None
        self.templates = {}
        
        # DeepSeek —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        self.deepseek_api_key = None
        self.deepseek_base_url = "https://api.deepseek.com/v1"
        
        self.setup_system()
    
    def load_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        default_config = {
            "embedding_model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "llm_model": "qwen2.5-coder-7b-instruct-q4_0.gguf",
            "llm_provider": "deepseek",  # local, deepseek, openai, azure
            "chunk_size": 1000,
            "chunk_overlap": 200,
            "max_results": 5,
            "temperature": 0.1,
            "max_tokens": 500,
            "deepseek_api_key": None,
            "deepseek_model": "deepseek-chat"
        }
        
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                default_config.update(user_config)
        except FileNotFoundError:
            logger.info("–ö–æ–Ω—Ñ–∏–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        
        return default_config
    
    def setup_system(self):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –õ–ü–ê/–õ–ù–ü–ê...")
        
        try:
            self.load_models()
            self.setup_vector_db()
            self.load_all_documents()
            self.load_templates()
            logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            raise
    
    def load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
        
        try:
            # –≠–º–±–µ–¥–¥–∏–Ω–≥ –º–æ–¥–µ–ª—å –≤—Å–µ–≥–¥–∞ –ª–æ–∫–∞–ª—å–Ω–∞—è
            self.embedding_model = SentenceTransformer(self.config["embedding_model"])
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM –∫–ª–∏–µ–Ω—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            llm_provider = self.config["llm_provider"]
            
            if llm_provider == "local":
                self.llm_client = GPT4All(self.config["llm_model"])
                logger.info("‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è LLM –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                
            elif llm_provider == "deepseek":
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è -> –∫–æ–Ω—Ñ–∏–≥ -> –æ—à–∏–±–∫–∞
                api_key = os.getenv("DEEPSEEK_API_KEY") or self.config["deepseek_api_key"]
                if not api_key:
                    raise ValueError("DeepSeek API key not found. Set DEEPSEEK_API_KEY environment variable or add to config")
                
                self.llm_client = None  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∏–µ–Ω—Ç –¥–ª—è DeepSeek
                self.llm_model = os.getenv("DEEPSEEK_MODEL") or self.config.get("deepseek_model", "deepseek-chat")
                self.deepseek_api_key = api_key
                
                logger.info(f"‚úÖ DeepSeek –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–º–æ–¥–µ–ª—å: {self.llm_model})")
                
            elif llm_provider == "openai":
                # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è OpenAI (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ)
                logger.info("‚úÖ OpenAI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≤—ã–±—Ä–∞–Ω")
                # self.llm_client = openai.OpenAI(api_key=...)
                
            else:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä LLM: {llm_provider}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            raise

    def _call_deepseek_api(self, prompt: str, max_tokens: int = 500, temperature: float = 0.1) -> str:
        """–ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ DeepSeek API —á–µ—Ä–µ–∑ HTTP –∑–∞–ø—Ä–æ—Å—ã"""
        url = f"{self.deepseek_base_url}/chat/completions"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.deepseek_api_key}"
        }
        
        data = {
            "model": self.llm_model,
            "messages": [
                {
                    "role": "system", 
                    "content": "–¢—ã - AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º–∏ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –õ–ü–ê/–õ–ù–ü–ê. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –∏ –ø–æ –¥–µ–ª—É."
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "max_tokens": max_tokens,
            "temperature": temperature,
            "stream": False
        }
        
        try:
            response = requests.post(url, headers=headers, json=data, timeout=60)
            response.raise_for_status()
            
            result = response.json()
            
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content']
            else:
                logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ DeepSeek: {result}")
                return "–û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"
                
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ DeepSeek API: {e}")
            return f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å DeepSeek API: {e}"
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç–≤–µ—Ç–∞: {e}")
            return "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"
        except Exception as e:
            logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ DeepSeek API: {e}")
            return f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}"

    def generate_with_online_model(self, prompt: str, max_tokens: int = 500, temperature: float = 0.1) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–Ω–ª–∞–π–Ω-–º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ HTTP –∑–∞–ø—Ä–æ—Å—ã"""
        try:
            llm_provider = self.config["llm_provider"]
            
            if llm_provider == "deepseek":
                return self._call_deepseek_api(prompt, max_tokens, temperature)
                
            elif llm_provider in ["openai", "azure"]:
                # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∑–¥–µ—Å—å
                return f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {llm_provider} –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"
                
            else:
                return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä LLM"
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –æ–Ω–ª–∞–π–Ω-–º–æ–¥–µ–ª—å—é: {e}")
            return f"–û—à–∏–±–∫–∞: {e}"
    
    def setup_vector_db(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
        try:
            self.vector_db = chromadb.PersistentClient(path=self.persist_dir)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
            try:
                self.collection = self.vector_db.get_collection("lnp_documents")
                logger.info("üìä –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            except Exception as e:
                logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                self.collection = self.vector_db.create_collection(
                    name="lnp_documents",
                    metadata={"description": "–ë–∞–∑–∞ –õ–ü–ê/–õ–ù–ü–ê –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", "created": datetime.now().isoformat()}
                )
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ë–î: {e}")
            raise
    
    def extract_text_from_pdf(self, filepath: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
        try:
            with open(filepath, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                for page in reader.pages:
                    text += page.extract_text() + "\n"
                return text
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF {filepath}: {e}")
            return ""
    
    def extract_text_from_docx(self, filepath: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX"""
        try:
            doc = Document(filepath)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX {filepath}: {e}")
            return ""
    
    def get_file_hash(self, filepath: str) -> str:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö–µ—à–∞ —Ñ–∞–π–ª–∞"""
        try:
            with open(filepath, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö–µ—à–∞ {filepath}: {e}")
            return ""
    
    def document_exists(self, filename: str, file_hash: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –ë–î"""
        try:
            # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∏–ª—å—Ç—Ä–∞ –¥–ª—è ChromaDB
            results = self.collection.get(
                where={"filename": {"$eq": filename}},
                limit=1
            )
            
            if results['ids']:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ö–µ—à –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞
                first_metadata = results['metadatas'][0]
                if 'file_hash' in first_metadata and first_metadata['file_hash'] == file_hash:
                    return True
            return False
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {filename}: {e}")
            return False
    
    def smart_chunking(self, text: str, filename: str) -> List[DocumentChunk]:
        """–£–º–Ω–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        text = re.sub(r'\s+', ' ', text).strip()
        
        if not text:
            return []
        
        chunks = []
        chunk_size = self.config["chunk_size"]
        overlap = self.config["chunk_overlap"]
        
        # –ü—Ä–æ—Å—Ç–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        for i in range(0, len(text), chunk_size - overlap):
            chunk_text = text[i:i + chunk_size]
            if len(chunk_text) > 100:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
                chunks.append(DocumentChunk(
                    text=chunk_text,
                    metadata={
                        'filename': filename,
                        'chunk_id': len(chunks),
                        'start_char': i,
                        'end_char': i + len(chunk_text)
                    }
                ))
        
        return chunks
    
    def load_all_documents(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {self.data_dir}")
            return
        
        supported_extensions = ['.txt', '.pdf', '.docx']
        files = []
        
        for ext in supported_extensions:
            files.extend([f for f in os.listdir(self.data_dir) if f.lower().endswith(ext)])
        
        logger.info(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        total_loaded = 0
        for filename in files:
            if self.process_document(filename):
                total_loaded += 1
        
        logger.info(f"üéØ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_loaded} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    def process_document(self, filename: str) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        filepath = os.path.join(self.data_dir, filename)
        
        if not os.path.exists(filepath):
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {filename} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–µ—à–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        file_hash = self.get_file_hash(filepath)
        if not file_hash:
            return False
        
        if self.document_exists(filename, file_hash):
            logger.info(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç {filename} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
            return True
        
        try:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            text = ""
            if filename.lower().endswith('.txt'):
                with open(filepath, 'r', encoding='utf-8') as f:
                    text = f.read()
            elif filename.lower().endswith('.pdf'):
                text = self.extract_text_from_pdf(filepath)
            elif filename.lower().endswith('.docx'):
                text = self.extract_text_from_docx(filepath)
            
            if not text:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ {filename}")
                return False
            
            # –ß–∞–Ω–∫–æ–≤–∞–Ω–∏–µ
            chunks = self.smart_chunking(text, filename)
            if not chunks:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –Ω–∞ —á–∞–Ω–∫–∏ {filename}")
                return False
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
            self.add_chunks_to_db(chunks, filename, file_hash)
            logger.info(f"‚úÖ {filename} - {len(chunks)} —á–∞–Ω–∫–æ–≤")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {filename}: {e}")
            return False
    
    def add_chunks_to_db(self, chunks: List[DocumentChunk], filename: str, file_hash: str):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –≤ –ë–î"""
        texts = [chunk.text for chunk in chunks]
        
        try:
            embeddings = self.embedding_model.encode(texts).tolist()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {filename}: {e}")
            return
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadatas = []
        ids = []
        
        for i, chunk in enumerate(chunks):
            metadata = chunk.metadata.copy()
            metadata.update({
                'file_hash': file_hash,
                'timestamp': datetime.now().isoformat()
            })
            metadatas.append(metadata)
            ids.append(f"{filename}_{i}_{hashlib.md5(chunk.text.encode()).hexdigest()[:8]}")
        
        try:
            self.collection.add(
                embeddings=embeddings,
                documents=texts,
                metadatas=metadatas,
                ids=ids
            )
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ë–î: {e}")
    
    def semantic_search(self, query: str, n_results: int = 3) -> List[Tuple[str, Dict]]:
        """–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            query_embedding = self.embedding_model.encode([query]).tolist()
            
            results = self.collection.query(
                query_embeddings=query_embedding,
                n_results=n_results
            )
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            formatted_results = []
            for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):
                formatted_results.append((doc, metadata))
            
            return formatted_results
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def ask_question(self, question: str) -> Dict:
        """–û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        start_time = time.time()
        
        # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        search_results = self.semantic_search(question, n_results=3)
        
        if not search_results:
            return {
                "answer": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö.",
                "sources": [],
                "response_time": time.time() - start_time
            }
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_parts = []
        sources = []
        
        for i, (text, metadata) in enumerate(search_results):
            context_parts.append(f"[–î–æ–∫—É–º–µ–Ω—Ç {i+1}: {metadata['filename']}]\n{text}")
            sources.append({
                "filename": metadata['filename'],
                "chunk_id": metadata['chunk_id'],
                "text_excerpt": text[:200] + "..."
            })
        
        context = "\n\n".join(context_parts)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ —Ü–∏—Ç–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç—ã.

–î–æ–∫—É–º–µ–Ω—Ç—ã:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
1. –û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
2. –£–∫–∞–∂–∏ –Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç - —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º
4. –ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º

–û—Ç–≤–µ—Ç:"""
        
        try:
            llm_provider = self.config["llm_provider"]
            
            if llm_provider == "local":
                answer = self.llm_client.generate(prompt, max_tokens=300, temp=0.1)
            else:
                answer = self.generate_with_online_model(prompt, max_tokens=300, temperature=0.1)
            
            return {
                "answer": answer.strip(),
                "sources": sources,
                "response_time": time.time() - start_time
            }
            
        except Exception as e:
            return {
                "answer": f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}",
                "sources": [],
                "response_time": time.time() - start_time
            }
    
    def load_templates(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        templates_dir = "templates"
        if not os.path.exists(templates_dir):
            os.makedirs(templates_dir)
            # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤
            self.create_default_templates(templates_dir)
        
        template_files = [f for f in os.listdir(templates_dir) if f.endswith('.json')]
        
        for template_file in template_files:
            filepath = os.path.join(templates_dir, template_file)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    template_name = template_file.replace('.json', '')
                    self.templates[template_name] = json.load(f)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —à–∞–±–ª–æ–Ω–∞ {template_file}: {e}")
        
        logger.info(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.templates)} —à–∞–±–ª–æ–Ω–æ–≤")
    
    def create_default_templates(self, templates_dir):
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤"""
        # –®–∞–±–ª–æ–Ω –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è
        tz_template = {
            "name": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ",
            "sections": [
                {"name": "–û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è", "fields": ["–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–æ—Å–Ω–æ–≤–∞–Ω–∏–µ", "—Ü–µ–ª–∏"]},
                {"name": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è", "fields": ["—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è", "—Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã", "—Å—Ä–æ–∫–∏"]},
                {"name": "–ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–µ–º–∫–∏", "fields": ["–ø—Ä–æ—Ü–µ–¥—É—Ä–∞", "–∫—Ä–∏—Ç–µ—Ä–∏–∏", "–¥–æ–∫—É–º–µ–Ω—Ç—ã"]}
            ],
            "prompt": "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π: {context}"
        }
        
        try:
            with open(os.path.join(templates_dir, "–¢–ó.json"), 'w', encoding='utf-8') as f:
                json.dump(tz_template, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —à–∞–±–ª–æ–Ω–∞ –¢–ó: {e}")
    
    def generate_document(self, doc_type: str, requirements: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ —à–∞–±–ª–æ–Ω—É"""
        if doc_type not in self.templates:
            return {"error": f"–®–∞–±–ª–æ–Ω {doc_type} –Ω–µ –Ω–∞–π–¥–µ–Ω"}
        
        template = self.templates[doc_type]
        
        # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        search_results = self.semantic_search(requirements, n_results=2)
        context = " ".join([text for text, _ in search_results])
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞
        prompt = template["prompt"].format(context=context, requirements=requirements)
        
        try:
            llm_provider = self.config["llm_provider"]
            
            if llm_provider == "local":
                generated_content = self.llm_client.generate(prompt, max_tokens=500, temp=0.2)
            else:
                generated_content = self.generate_with_online_model(prompt, max_tokens=500, temperature=0.2)
            
            return {
                "document_type": doc_type,
                "content": generated_content.strip(),
                "sections": template["sections"],
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"error": f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"}
    
    def interactive_mode(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"""
        print("\n" + "="*60)
        print("ü§ñ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –õ–ü–ê/–õ–ù–ü–ê –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        print(f"üì° –†–µ–∂–∏–º: {self.config['llm_provider']}")
        print("–ö–æ–º–∞–Ω–¥—ã:")
        print("  /–≤–æ–ø—Ä–æ—Å [—Ç–µ–∫—Å—Ç] - –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å")
        print("  /–≥–µ–Ω–µ—Ä–∞—Ü–∏—è [—Ç–∏–ø] [—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è] - —Å–æ–∑–¥–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç")
        print("  /—à–∞–±–ª–æ–Ω—ã - —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤")
        print("  /—Å—Ç–∞—Ç—É—Å - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ")
        print("  /–≤—ã—Ö–æ–¥ - –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É")
        print("="*60)
        
        while True:
            try:
                user_input = input("\nüéØ –í–≤–µ–¥–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É: ").strip()
                
                if user_input.lower() in ['/–≤—ã—Ö–æ–¥', '/exit']:
                    break
                
                elif user_input.startswith('/–≤–æ–ø—Ä–æ—Å '):
                    question = user_input[8:].strip()
                    if question:
                        result = self.ask_question(question)
                        print(f"\nü§ñ –û—Ç–≤–µ—Ç ({result['response_time']:.1f}—Å–µ–∫):")
                        print(result['answer'])
                        if result['sources']:
                            print("\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
                            for source in result['sources']:
                                print(f"   - {source['filename']} (—Ñ—Ä–∞–≥–º–µ–Ω—Ç {source['chunk_id']})")
                
                elif user_input.startswith('/–≥–µ–Ω–µ—Ä–∞—Ü–∏—è '):
                    parts = user_input[11:].split(' ', 1)
                    if len(parts) == 2:
                        doc_type, requirements = parts
                        result = self.generate_document(doc_type, requirements)
                        if 'error' not in result:
                            print(f"\nüìÑ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –¥–æ–∫—É–º–µ–Ω—Ç: {result['document_type']}")
                            print(result['content'])
                        else:
                            print(f"‚ùå {result['error']}")
                    else:
                        print("‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /–≥–µ–Ω–µ—Ä–∞—Ü–∏—è [—Ç–∏–ø] [—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è]")
                
                elif user_input == '/—à–∞–±–ª–æ–Ω—ã':
                    print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã:")
                    for template in self.templates.keys():
                        print(f"   - {template}")
                
                elif user_input == '/—Å—Ç–∞—Ç—É—Å':
                    try:
                        count = self.collection.count()
                        print(f"\nüìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:")
                        print(f"   –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {count}")
                        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤: {len(self.templates)}")
                        print(f"   –ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM: {self.config['llm_provider']}")
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
                
                else:
                    print("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞")
                    
            except KeyboardInterrupt:
                print("\nüëã –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
                break
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        assistant = EnhancedLNPAssistant()
        assistant.interactive_mode()
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())